import json
import os
import re
import sys
import urllib.parse
from pathlib import Path

BACKEND_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
if BACKEND_ROOT not in sys.path:
    sys.path.insert(0, BACKEND_ROOT)

from db.connection import get_db_connection
from utils.logger import log_info, log_error
from utils.utils import map_image_path


IMAGE_EXTENSIONS = {".webp", ".jpg", ".jpeg", ".png", ".avif"}


def _project_root() -> Path:
    return Path(__file__).resolve().parents[3]


def _load_locale_items(relative_path: str):
    file_path = _project_root() / relative_path
    if not file_path.exists():
        log_error(f"‚ùå Locale seed file not found: {file_path}", "maintenance")
        return []

    try:
        with open(file_path, "r", encoding="utf-8") as file:
            payload = json.load(file)
            items = payload.get("items", [])
            return items if isinstance(items, list) else []
    except Exception as exc:
        log_error(f"‚ùå Failed to parse locale seed file {file_path}: {exc}", "maintenance")
        return []


def _normalize_text(value: str) -> str:
    raw_value = (value or "").lower().strip()
    if not raw_value:
        return ""
    clean_value = re.sub(r"[^\w\s–∞-—è—ë]", " ", raw_value, flags=re.IGNORECASE)
    return re.sub(r"\s+", " ", clean_value).strip()


def _iter_image_files(directory: Path):
    if not directory.exists() or not directory.is_dir():
        return []

    files = []
    for file_path in sorted(directory.iterdir(), key=lambda p: p.name.lower()):
        if not file_path.is_file():
            continue
        if file_path.name.startswith("."):
            continue
        if file_path.suffix.lower() not in IMAGE_EXTENSIONS:
            continue
        files.append(file_path)
    return files


def _humanize_filename(file_name: str, fallback: str) -> str:
    stem = Path(file_name).stem.replace("_", " ").replace("-", " ").strip()
    stem = re.sub(r"\s+", " ", stem)
    if not stem:
        return fallback
    if stem.islower():
        return stem.capitalize()
    return stem


def _gallery_dedupe_key(category: str, image_url: str) -> str:
    mapped_url = map_image_path(image_url or "") or (image_url or "")
    decoded_path = urllib.parse.unquote(mapped_url)
    stem = Path(decoded_path).stem.lower()
    stem = stem.replace("_", " ").replace("-", " ")
    stem = re.sub(r"\s+", " ", stem).strip()
    compact_stem = re.sub(r"[^0-9a-z–∞-—è—ë]", "", stem, flags=re.IGNORECASE)
    if compact_stem:
        return f"{category}:{compact_stem}"
    return f"{category}:{mapped_url.lower().strip()}"


def _collect_gallery_candidates():
    root = _project_root()
    source_config = {
        "salon": [
            (root / "frontend/public_landing/styles/img/salon", "/landing-images/salon"),
        ],
        "portfolio": [
            (root / "frontend/public_landing/styles/img/portfolio", "/landing-images/portfolio"),
        ],
    }

    defaults = {
        "salon": ("–§–æ—Ç–æ —Å–∞–ª–æ–Ω–∞", "–ò–Ω—Ç–µ—Ä—å–µ—Ä —Å–∞–ª–æ–Ω–∞"),
        "portfolio": ("–ü–æ—Ä—Ç—Ñ–æ–ª–∏–æ", "–†–∞–±–æ—Ç—ã —Å–∞–ª–æ–Ω–∞"),
    }

    seen_keys = set()
    candidates = {category: [] for category in source_config.keys()}

    for category, sources in source_config.items():
        default_title, default_description = defaults[category]
        for directory, url_prefix in sources:
            for file_path in _iter_image_files(directory):
                raw_url = f"{url_prefix}/{file_path.name}"
                key = _gallery_dedupe_key(category, raw_url)
                if key in seen_keys:
                    continue

                seen_keys.add(key)
                public_url = map_image_path(raw_url) or raw_url
                candidates[category].append({
                    "key": key,
                    "category": category,
                    "image_url": public_url,
                    "title": _humanize_filename(file_path.name, default_title),
                    "description": default_description,
                })

    return candidates


def _sync_gallery_from_folders(cursor):
    candidates_by_category = _collect_gallery_candidates()
    categories_to_sync = [cat for cat, items in candidates_by_category.items() if items]
    if not categories_to_sync:
        log_info("   ‚ö†Ô∏è Gallery sync skipped: source folders are empty", "maintenance")
        return 0

    candidate_by_key = {}
    ordered_keys = []
    for category in categories_to_sync:
        for item in candidates_by_category[category]:
            candidate_by_key[item["key"]] = item
            ordered_keys.append(item["key"])

    candidate_keys = set(candidate_by_key.keys())
    cursor.execute(
        """
            SELECT id, image_url, title, description, category, display_order, is_active
            FROM public_gallery
            WHERE category = ANY(%s)
            ORDER BY category ASC, is_active DESC, display_order ASC, id ASC
        """,
        (categories_to_sync,),
    )
    existing_rows = cursor.fetchall()

    keep_by_key = {}
    ids_to_delete = []

    for row in existing_rows:
        row_id, image_url, _, _, category, _, _ = row
        key = _gallery_dedupe_key(category, image_url or "")
        if key not in candidate_keys:
            ids_to_delete.append(row_id)
            continue
        if key in keep_by_key:
            ids_to_delete.append(row_id)
            continue
        keep_by_key[key] = row

    deleted = 0
    if ids_to_delete:
        cursor.execute("DELETE FROM public_gallery WHERE id = ANY(%s)", (ids_to_delete,))
        deleted = len(ids_to_delete)

    display_order_by_category = {category: 0 for category in categories_to_sync}
    inserted = 0
    updated = 0

    for key in ordered_keys:
        item = candidate_by_key[key]
        category = item["category"]
        display_order_by_category[category] += 1
        target_order = display_order_by_category[category]

        existing_row = keep_by_key.get(key)
        if existing_row:
            row_id, image_url, title, description, _, current_order, is_active = existing_row
            if (
                (image_url or "") != item["image_url"]
                or (title or "") != item["title"]
                or (description or "") != item["description"]
                or (current_order or 0) != target_order
                or is_active is not True
            ):
                cursor.execute(
                    """
                        UPDATE public_gallery
                        SET image_url = %s,
                            title = %s,
                            description = %s,
                            display_order = %s,
                            is_active = TRUE
                        WHERE id = %s
                    """,
                    (
                        item["image_url"],
                        item["title"],
                        item["description"],
                        target_order,
                        row_id,
                    ),
                )
                updated += 1
            continue

        cursor.execute(
            """
                INSERT INTO public_gallery (
                    image_url, title, description, category, display_order, is_active
                )
                VALUES (%s, %s, %s, %s, %s, TRUE)
            """,
            (
                item["image_url"],
                item["title"],
                item["description"],
                category,
                target_order,
            ),
        )
        inserted += 1

    if inserted or updated or deleted:
        log_info(
            f"   ‚úÖ Gallery sync: inserted={inserted}, updated={updated}, deleted_duplicates={deleted}",
            "maintenance",
        )
    else:
        log_info("   ‚úÖ Gallery sync: no changes", "maintenance")

    return inserted + updated + deleted


def _collect_banner_candidates():
    root = _project_root()
    banners_dir = root / "frontend/public_landing/styles/img/banners"
    files = _iter_image_files(banners_dir)
    if not files:
        return []

    candidates = []
    seen_urls = set()
    for index, file_path in enumerate(files, start=1):
        image_url = f"/landing-images/banners/{file_path.name}"
        normalized_url = image_url.strip().lower()
        if normalized_url in seen_urls:
            continue
        seen_urls.add(normalized_url)

        candidates.append(
            {
                "image_url": image_url,
                "title": "–°–∞–ª–æ–Ω –∫—Ä–∞—Å–æ—Ç—ã –≤ –î—É–±–∞–µ" if index == 1 else _humanize_filename(file_path.name, "–ë–∞–Ω–Ω–µ—Ä —Å–∞–ª–æ–Ω–∞"),
                "subtitle": "–ò—Å–∫—É—Å—Å—Ç–≤–æ –ø—Ä–µ–æ–±—Ä–∞–∂–µ–Ω–∏—è" if index == 1 else "",
                "display_order": len(candidates) + 1,
            }
        )
    return candidates


def _sync_banners_from_folder(cursor):
    candidates = _collect_banner_candidates()
    if not candidates:
        log_info("   ‚ö†Ô∏è Banner sync skipped: banners folder is empty", "maintenance")
        return 0

    cursor.execute(
        """
            SELECT id, image_url, title, subtitle, display_order, is_active
            FROM public_banners
            ORDER BY display_order ASC, id ASC
        """
    )
    existing_rows = cursor.fetchall()

    candidate_urls = {(item["image_url"] or "").strip().lower() for item in candidates}
    existing_by_url = {}
    ids_to_delete = []

    for row_id, image_url, title, subtitle, display_order, is_active in existing_rows:
        normalized_url = (image_url or "").strip().lower()
        if not normalized_url or normalized_url not in candidate_urls:
            ids_to_delete.append(row_id)
            continue
        if normalized_url in existing_by_url:
            ids_to_delete.append(row_id)
            continue
        existing_by_url[normalized_url] = (row_id, image_url, title, subtitle, display_order, is_active)

    deleted = 0
    if ids_to_delete:
        cursor.execute("DELETE FROM public_banners WHERE id = ANY(%s)", (ids_to_delete,))
        deleted = len(ids_to_delete)

    inserted = 0
    updated = 0
    for candidate in candidates:
        normalized_url = (candidate["image_url"] or "").strip().lower()
        existing = existing_by_url.get(normalized_url)
        if existing:
            row_id, image_url, title, subtitle, display_order, is_active = existing
            target_title = title if (title or "").strip() else candidate["title"]
            target_subtitle = subtitle if (subtitle or "").strip() else candidate["subtitle"]
            target_order = candidate["display_order"]
            if (
                (image_url or "") != candidate["image_url"]
                or (title or "") != target_title
                or (subtitle or "") != target_subtitle
                or (display_order or 0) != target_order
                or is_active is not True
            ):
                cursor.execute(
                    """
                        UPDATE public_banners
                        SET image_url = %s,
                            title = %s,
                            subtitle = %s,
                            display_order = %s,
                            is_active = TRUE
                        WHERE id = %s
                    """,
                    (candidate["image_url"], target_title, target_subtitle, target_order, row_id),
                )
                updated += 1
            continue

        cursor.execute(
            """
                INSERT INTO public_banners (image_url, title, subtitle, is_active, display_order)
                VALUES (%s, %s, %s, TRUE, %s)
            """,
            (candidate["image_url"], candidate["title"], candidate["subtitle"], candidate["display_order"]),
        )
        inserted += 1

    if inserted or updated or deleted:
        log_info(
            f"   ‚úÖ Banner sync: inserted={inserted}, updated={updated}, deleted={deleted}",
            "maintenance",
        )
    else:
        log_info("   ‚úÖ Banner sync: no changes", "maintenance")

    return inserted + updated + deleted


def _faq_group_key(question: str) -> str:
    normalized_question = _normalize_text(question)
    if not normalized_question:
        return ""

    if "–∑–∞–ø–∏—Å" in normalized_question:
        return "booking"

    if "–æ—Ç–º–µ–Ω" in normalized_question or "–ø–µ—Ä–µ–Ω–µ—Å" in normalized_question:
        return "reschedule"

    if "–º–∞—Ç–µ—Ä–∏–∞–ª" in normalized_question or "–±—Ä–µ–Ω–¥" in normalized_question:
        return "materials"

    if "–≥–¥–µ" in normalized_question and ("–Ω–∞—Ö–æ–¥" in normalized_question or "–∞–¥—Ä–µ—Å" in normalized_question):
        return "location"

    return ""


def _contains_hardcoded_brands(question: str, answer: str) -> bool:
    combined = _normalize_text(f"{question} {answer}")
    return "luxio" in combined or "fedua" in combined


def _cleanup_existing_public_reviews(cursor) -> int:
    cursor.execute(
        """
            SELECT id, author_name, text
            FROM public_reviews
            WHERE is_active = TRUE
            ORDER BY display_order ASC, id ASC
        """
    )
    rows = cursor.fetchall()
    if not rows:
        return 0

    ids_to_delete = []
    seen_authors = set()
    seen_texts = set()

    for row_id, author_name, review_text in rows:
        author_key = _normalize_text(author_name)
        text_key = _normalize_text(review_text)

        if text_key and text_key in seen_texts:
            ids_to_delete.append(row_id)
            continue

        if author_key and author_key in seen_authors:
            ids_to_delete.append(row_id)
            continue

        if author_key:
            seen_authors.add(author_key)
        if text_key:
            seen_texts.add(text_key)

    if not ids_to_delete:
        return 0

    cursor.execute("DELETE FROM public_reviews WHERE id = ANY(%s)", (ids_to_delete,))
    return len(ids_to_delete)


def _cleanup_existing_public_faq(cursor) -> int:
    cursor.execute(
        """
            SELECT id, question, answer
            FROM public_faq
            WHERE is_active = TRUE
            ORDER BY display_order ASC, id ASC
        """
    )
    rows = cursor.fetchall()
    if not rows:
        return 0

    ids_to_delete = []
    seen_questions = set()
    seen_groups = set()

    for row_id, question, answer in rows:
        question_key = _normalize_text(question)
        if not question_key:
            ids_to_delete.append(row_id)
            continue

        if _contains_hardcoded_brands(question, answer):
            ids_to_delete.append(row_id)
            continue

        if question_key in seen_questions:
            ids_to_delete.append(row_id)
            continue

        group_key = _faq_group_key(question)
        if group_key and group_key in seen_groups:
            ids_to_delete.append(row_id)
            continue

        seen_questions.add(question_key)
        if group_key:
            seen_groups.add(group_key)

    if not ids_to_delete:
        return 0

    cursor.execute("DELETE FROM public_faq WHERE id = ANY(%s)", (ids_to_delete,))
    return len(ids_to_delete)


def _seed_services_if_empty(cursor) -> int:
    cursor.execute("SELECT COUNT(*) FROM services WHERE is_active = TRUE")
    active_services = cursor.fetchone()[0]
    if active_services > 0:
        log_info(f"   ‚úÖ Services already present: {active_services}", "maintenance")
        return 0

    from scripts.testing.data.seed_test_data import SERVICES_DATA

    inserted = 0
    for service in SERVICES_DATA:
        cursor.execute(
            """
                INSERT INTO services (
                    service_key, name, category, price, min_price, max_price,
                    currency, duration, description, is_active
                )
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, TRUE)
                ON CONFLICT (service_key) DO NOTHING
            """,
            (
                service.get("key"),
                service.get("name"),
                service.get("category"),
                service.get("price"),
                service.get("min_price"),
                service.get("max_price"),
                service.get("currency", "AED"),
                service.get("duration"),
                service.get("description"),
            ),
        )
        if cursor.rowcount > 0:
            inserted += 1

    log_info(f"   ‚ûï Seeded services catalog: {inserted}", "maintenance")
    return inserted


def _normalize_core_service_names(cursor) -> int:
    """Keep critical service names consistent at source level (DB)."""
    updates = [
        ("repair_extension", "–ö–æ—Ä—Ä–µ–∫—Ü–∏—è 1 –Ω–∞—Ä–∞—â–µ–Ω–Ω–æ–≥–æ –Ω–æ–≥—Ç—è"),
        ("repair_gel", "–ö–æ—Ä—Ä–µ–∫—Ü–∏—è 1 –≥–µ–ª–µ–≤–æ–≥–æ –Ω–æ–≥—Ç—è"),
        ("peeling", "–ü–∏–ª–∏–Ω–≥"),
        ("nail_extensions", "–ù–∞—Ä–∞—â–∏–≤–∞–Ω–∏–µ –Ω–æ–≥—Ç–µ–π (–≥–µ–ª—å)"),
    ]

    updated = 0
    for service_key, target_name in updates:
        cursor.execute(
            """
                UPDATE services
                SET name = %s
                WHERE service_key = %s
                  AND COALESCE(name, '') <> %s
            """,
            (target_name, service_key, target_name),
        )
        updated += cursor.rowcount

    legacy_renames = [
        ("–†–µ–º–æ–Ω—Ç 1 –Ω–∞—Ä–∞—â–∏–≤–∞–Ω–∏—è", "–ö–æ—Ä—Ä–µ–∫—Ü–∏—è 1 –Ω–∞—Ä–∞—â–µ–Ω–Ω–æ–≥–æ –Ω–æ–≥—Ç—è"),
        ("Repair 1 Extension", "–ö–æ—Ä—Ä–µ–∫—Ü–∏—è 1 –Ω–∞—Ä–∞—â–µ–Ω–Ω–æ–≥–æ –Ω–æ–≥—Ç—è"),
        ("–†–µ–º–æ–Ω—Ç 1 –≥–µ–ª–µ–≤–æ–≥–æ –Ω–æ–≥—Ç–µ–π", "–ö–æ—Ä—Ä–µ–∫—Ü–∏—è 1 –≥–µ–ª–µ–≤–æ–≥–æ –Ω–æ–≥—Ç—è"),
        ("–†–µ–º–æ–Ω—Ç 1 –≥–µ–ª–µ–≤–æ–≥–æ –Ω–æ–≥—Ç—è", "–ö–æ—Ä—Ä–µ–∫—Ü–∏—è 1 –≥–µ–ª–µ–≤–æ–≥–æ –Ω–æ–≥—Ç—è"),
        ("Repair 1 Gel Nail", "–ö–æ—Ä—Ä–µ–∫—Ü–∏—è 1 –≥–µ–ª–µ–≤–æ–≥–æ –Ω–æ–≥—Ç—è"),
        ("–ø–∏–ª–∏–Ω–≥", "–ü–∏–ª–∏–Ω–≥"),
        ("Peeling", "–ü–∏–ª–∏–Ω–≥"),
        ("–Ω–∞—Ä–∞—â–∏–≤–∞–Ω–∏–µ –Ω–æ–≥—Ç–µ–π (–≥–µ–ª—å)", "–ù–∞—Ä–∞—â–∏–≤–∞–Ω–∏–µ –Ω–æ–≥—Ç–µ–π (–≥–µ–ª—å)"),
    ]

    for old_name, new_name in legacy_renames:
        cursor.execute(
            """
                UPDATE services
                SET name = %s
                WHERE name = %s
            """,
            (new_name, old_name),
        )
        updated += cursor.rowcount

    if updated > 0:
        log_info(f"   ‚úÖ Normalized critical service names: {updated}", "maintenance")

    return updated


def _seed_gallery_if_empty(cursor) -> int:
    cursor.execute("SELECT COUNT(*) FROM public_gallery WHERE is_active = TRUE")
    active_gallery = cursor.fetchone()[0]
    if active_gallery > 0:
        log_info(f"   ‚úÖ Public gallery already present: {active_gallery}", "maintenance")
        return 0

    gallery_items = [
        # Portfolio
        ("/landing-images/portfolio/Manicure.webp", "–ú–∞–Ω–∏–∫—é—Ä", "–†–∞–±–æ—Ç–∞ –Ω–∞—à–∏—Ö –º–∞—Å—Ç–µ—Ä–æ–≤", "portfolio", 1),
        ("/landing-images/portfolio/Hair.webp", "–£–∫–ª–∞–¥–∫–∞ –≤–æ–ª–æ—Å", "–ü—Ä–µ–º–∏–∞–ª—å–Ω–∞—è —É–∫–ª–∞–¥–∫–∞", "portfolio", 2),
        ("/landing-images/portfolio/SPA3.webp", "SPA —É—Ö–æ–¥", "–†–µ–ª–∞–∫—Å –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ", "portfolio", 3),
        ("/landing-images/portfolio/Permanent_lips.webp", "–ü–µ—Ä–º–∞–Ω–µ–Ω—Ç–Ω—ã–π –º–∞–∫–∏—è–∂", "–ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç", "portfolio", 4),
        # Salon
        ("/landing-images/salon/1.webp", "–ò–Ω—Ç–µ—Ä—å–µ—Ä —Å–∞–ª–æ–Ω–∞", "–ö–æ–º—Ñ–æ—Ä—Ç–Ω–∞—è –∞—Ç–º–æ—Å—Ñ–µ—Ä–∞", "salon", 1),
        ("/landing-images/salon/2.webp", "–ó–æ–Ω–∞ –æ–∂–∏–¥–∞–Ω–∏—è", "–£—é—Ç –∏ —Å–µ—Ä–≤–∏—Å", "salon", 2),
        ("/landing-images/salon/4.webp", "–†–∞–±–æ—á–∞—è –∑–æ–Ω–∞", "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ", "salon", 3),
        ("/landing-images/salon/8.webp", "–ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ —Å–∞–ª–æ–Ω–∞", "–ü—Ä–µ–º–∏–∞–ª—å–Ω—ã–π –¥–∏–∑–∞–π–Ω", "salon", 4),
    ]

    inserted = 0
    for image_url, title, description, category, display_order in gallery_items:
        cursor.execute(
            """
                SELECT 1
                FROM public_gallery
                WHERE image_url = %s AND category = %s
                LIMIT 1
            """,
            (image_url, category),
        )
        if cursor.fetchone():
            continue

        cursor.execute(
            """
                INSERT INTO public_gallery (
                    image_url, title, description, category, display_order, is_active
                )
                VALUES (%s, %s, %s, %s, %s, TRUE)
            """,
            (image_url, title, description, category, display_order),
        )
        inserted += 1

    log_info(f"   ‚ûï Seeded gallery items: {inserted}", "maintenance")
    return inserted


def _seed_faq_if_empty(cursor) -> int:
    cursor.execute("SELECT COUNT(*) FROM public_faq WHERE is_active = TRUE")
    active_faq = cursor.fetchone()[0]
    if active_faq > 0:
        log_info(f"   ‚úÖ FAQ already present: {active_faq}", "maintenance")
        return 0

    faq_items = _load_locale_items("frontend/src/locales/ru/public_landing/faq.json")
    if not faq_items:
        faq_items = [
            {
                "question": "–ö–∞–∫ –∑–∞–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ –ø—Ä–æ—Ü–µ–¥—É—Ä—É?",
                "answer": "–í—ã –º–æ–∂–µ—Ç–µ –∑–∞–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ —Å–∞–π—Ç–µ, –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É –∏–ª–∏ —á–µ—Ä–µ–∑ WhatsApp.",
            },
            {
                "question": "–ú–æ–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –∑–∞–ø–∏—Å—å?",
                "answer": "–î–∞, –∑–∞–ø–∏—Å—å –º–æ–∂–Ω–æ –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –∑–∞—Ä–∞–Ω–µ–µ, —Å–≤—è–∂–∏—Ç–µ—Å—å —Å –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º.",
            },
            {
                "question": "–ö–∞–∫–∏–µ —Å–ø–æ—Å–æ–±—ã –æ–ø–ª–∞—Ç—ã –¥–æ—Å—Ç—É–ø–Ω—ã?",
                "answer": "–ú—ã –ø—Ä–∏–Ω–∏–º–∞–µ–º –Ω–∞–ª–∏—á–Ω—ã–µ –∏ –±–∞–Ω–∫–æ–≤—Å–∫–∏–µ –∫–∞—Ä—Ç—ã.",
            },
        ]

    inserted = 0
    seen_questions = set()
    seen_groups = set()
    for index, item in enumerate(faq_items, start=1):
        question = (item.get("question") or "").strip()
        answer = (item.get("answer") or "").strip()
        if not question or not answer:
            continue

        if _contains_hardcoded_brands(question, answer):
            continue

        question_key = _normalize_text(question)
        if question_key in seen_questions:
            continue

        group_key = _faq_group_key(question)
        if group_key and group_key in seen_groups:
            continue

        cursor.execute(
            """
                INSERT INTO public_faq (
                    question, answer, category, display_order, is_active
                )
                VALUES (%s, %s, 'general', %s, TRUE)
            """,
            (question, answer, index),
        )
        seen_questions.add(question_key)
        if group_key:
            seen_groups.add(group_key)
        inserted += 1

    log_info(f"   ‚ûï Seeded FAQ items: {inserted}", "maintenance")
    return inserted


def _seed_reviews_if_empty(cursor) -> int:
    cursor.execute("SELECT COUNT(*) FROM public_reviews WHERE is_active = TRUE")
    active_reviews = cursor.fetchone()[0]
    if active_reviews > 0:
        log_info(f"   ‚úÖ Reviews already present: {active_reviews}", "maintenance")
        return 0

    review_items = _load_locale_items("frontend/src/locales/ru/public_landing/reviews.json")
    if not review_items:
        review_items = [
            {
                "author_name": "–ê–Ω–Ω–∞ –ü–µ—Ç—Ä–æ–≤–∞",
                "text": "–û—Ç–ª–∏—á–Ω—ã–π —Å–µ—Ä–≤–∏—Å –∏ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω—ã–µ –º–∞—Å—Ç–µ—Ä–∞. –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –¥–æ–≤–æ–ª—å–Ω–∞.",
                "employee_position": "–ú–∞–Ω–∏–∫—é—Ä –∏ –ø–µ–¥–∏–∫—é—Ä",
                "rating": 5,
            },
            {
                "author_name": "–ú–∞—Ä–∏—è –ì–æ–Ω—Å–∞–ª–µ—Å",
                "text": "–û—á–µ–Ω—å —É—é—Ç–Ω–∞—è –∞—Ç–º–æ—Å—Ñ–µ—Ä–∞ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∫–∞–∂–¥–æ–π –ø—Ä–æ—Ü–µ–¥—É—Ä–µ.",
                "employee_position": "–£—Ö–æ–¥ –∑–∞ –ª–∏—Ü–æ–º",
                "rating": 5,
            },
        ]

    inserted = 0
    seen_authors = set()
    seen_texts = set()
    for index, item in enumerate(review_items, start=1):
        text = (item.get("text") or "").strip()
        if not text:
            continue

        author_name = (item.get("author_name") or f"–ö–ª–∏–µ–Ω—Ç {index}").strip()
        author_key = _normalize_text(author_name)
        text_key = _normalize_text(text)
        if text_key in seen_texts or author_key in seen_authors:
            continue

        employee_name = (item.get("employee_name") or "").strip()
        employee_position = (item.get("employee_position") or "").strip()
        rating_raw = item.get("rating", 5)

        try:
            rating = int(rating_raw)
        except (TypeError, ValueError):
            rating = 5
        if rating < 1 or rating > 5:
            rating = 5

        cursor.execute(
            """
                INSERT INTO public_reviews (
                    author_name, employee_name, employee_position,
                    rating, text, avatar_url, is_active, display_order
                )
                VALUES (%s, %s, %s, %s, %s, NULL, TRUE, %s)
            """,
            (author_name, employee_name, employee_position, rating, text, index),
        )
        seen_authors.add(author_key)
        seen_texts.add(text_key)
        inserted += 1

    log_info(f"   ‚ûï Seeded reviews: {inserted}", "maintenance")
    return inserted


def seed_public_landing_baseline(cursor):
    log_info("üß© Verifying public landing baseline content...", "maintenance")

    try:
        _seed_services_if_empty(cursor)
    except Exception as exc:
        log_error(f"‚ùå Services baseline seed failed: {exc}", "maintenance")

    try:
        _seed_gallery_if_empty(cursor)
    except Exception as exc:
        log_error(f"‚ùå Gallery baseline seed failed: {exc}", "maintenance")

    try:
        _seed_faq_if_empty(cursor)
    except Exception as exc:
        log_error(f"‚ùå FAQ baseline seed failed: {exc}", "maintenance")

    try:
        _seed_reviews_if_empty(cursor)
    except Exception as exc:
        log_error(f"‚ùå Reviews baseline seed failed: {exc}", "maintenance")


def run_all_fixes():
    """Entry point for centralized maintenance runner"""
    return run_fix()

def run_fix():
    print("üöÄ Running system data maintenance...")

    conn = get_db_connection()
    c = conn.cursor()

    # Advisory lock to prevent multiple workers from running maintenance simultaneously
    c.execute("SELECT pg_try_advisory_lock(12346)")  # Different lock ID from init_database (12345)
    got_lock = c.fetchone()[0]
    if not got_lock:
        log_info("‚è≥ Another process is running maintenance, skipping...", "maintenance")
        conn.close()
        return True  # Return success - maintenance is being done by another worker

    try:
        # ONE-TIME CLEANUP: Remove duplicate reviews and clear bad banner/employee data
        log_info("üßπ Running data cleanup and synchronization...", "maintenance")

        # 1. Delete duplicate/weak public content
        deleted_reviews = _cleanup_existing_public_reviews(c)
        if deleted_reviews > 0:
            log_info(f"   ‚úÖ Removed {deleted_reviews} duplicate reviews", "maintenance")

        deleted_faq = _cleanup_existing_public_faq(c)
        if deleted_faq > 0:
            log_info(f"   ‚úÖ Removed {deleted_faq} duplicate/brand-hardcoded FAQ entries", "maintenance")

        # 2. Sync banners from a single SSOT source folder
        _sync_banners_from_folder(c)

        # 3. Clear employee photos that don't exist (404 paths)
        c.execute("""
            UPDATE users SET photo = NULL
            WHERE photo IS NOT NULL
              AND photo LIKE '%/employees/%'
              AND is_service_provider = TRUE
        """)
        if c.rowcount > 0:
            log_info(f"   ‚úÖ Cleared {c.rowcount} missing employee photos", "maintenance")

        # 3.1 Ensure salon branding defaults that must be prefilled via maintenance/migrations
        salon_instagram = os.getenv('SALON_INSTAGRAM', 'mlediamant').strip()
        if len(salon_instagram) == 0:
            salon_instagram = 'mlediamant'

        timezone_offset_raw = os.getenv('SALON_TIMEZONE_OFFSET', '4').strip()
        try:
            timezone_offset_value = int(float(timezone_offset_raw))
        except ValueError:
            timezone_offset_value = 4

        c.execute("""
            UPDATE salon_settings
            SET
                instagram = COALESCE(NULLIF(TRIM(instagram), ''), %s),
                timezone_offset = COALESCE(timezone_offset, %s),
                timezone = COALESCE(NULLIF(TRIM(timezone), ''), 'Asia/Dubai')
            WHERE id = 1
        """, (salon_instagram, timezone_offset_value))
        if c.rowcount > 0:
            log_info("   ‚úÖ Ensured salon Instagram and timezone defaults in salon_settings", "maintenance")

        # 4. Sync salon/portfolio gallery from source folders and remove duplicates
        _sync_gallery_from_folders(c)
        c.execute(
            """
                DELETE FROM public_gallery
                WHERE category IS NULL
                   OR category NOT IN ('salon', 'portfolio')
            """
        )
        if c.rowcount > 0:
            log_info(f"   ‚úÖ Removed {c.rowcount} non-landing gallery items", "maintenance")

        # 4.1 Seed landing content baseline if public tables are empty
        seed_public_landing_baseline(c)

        # 5. Sync Employee Photos & Detailed Info
        log_info("üë®‚Äçüíº Updating employee photos, bios and status...", "maintenance")
        employee_data = {
            'gulcehre': {
                'full_name': '–ö–∞—Å—ã–º–æ–≤–∞ –ì—É–ª—å—á–µ—Ö—Ä–µ',
                'photo': '/landing-images/staff/Gulya.webp',
                'nickname': 'Gulya',
                'email': 'gulcehraautova@gmail.com',
                'phone': '+971525814262',
                'bio': '–ì—É–ª—è ‚Äî –ø—Ä–∏–∑–Ω–∞–Ω–Ω—ã–π —ç–∫—Å–ø–µ—Ä—Ç –≤ –æ–±–ª–∞—Å—Ç–∏ –º–∞–Ω–∏–∫—é—Ä–∞, –¥–µ–ø–∏–ª—è—Ü–∏–∏ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —É—Ö–æ–¥–∞ –∑–∞ –ª–∏—Ü–æ–º —Å 8-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º. –ë–ª–∞–≥–æ–¥–∞—Ä—è —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ–º—É –≤–ª–∞–¥–µ–Ω–∏—é —Ç–µ—Ö–Ω–∏–∫–∞–º–∏ —ç—Å—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –≤–Ω–∏–º–∞–Ω–∏—é –∫ –¥–µ—Ç–∞–ª—è–º, –æ–Ω–∞ —Å–æ–∑–¥–∞–µ—Ç –±–µ–∑—É–ø—Ä–µ—á–Ω—ã–µ –æ–±—Ä–∞–∑—ã, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è –∫–∞–∂–¥–æ–º—É –∫–ª–∏–µ–Ω—Ç—É –≤—ã—Å–æ—á–∞–π—à–∏–π —É—Ä–æ–≤–µ–Ω—å –∑–∞–±–æ—Ç—ã –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥.',
                'specialization': '–ù–æ–≥—Ç–µ–≤–æ–π —Å–µ—Ä–≤–∏—Å, –î–µ–ø–∏–ª—è—Ü–∏—è, –ö–æ—Å–º–µ—Ç–æ–ª–æ–≥–∏—è, –ú–∞—Å—Å–∞–∂',
                'years_of_experience': 8
            },
            'mestan': {
                'full_name': 'Amandurdyyeva Mestan',
                'photo': '/landing-images/staff/Mestan.webp',
                'nickname': 'Mestan',
                'email': 'amandurdyyeva80@gmail.com',
                'phone': '+971501800346',
                'bio': '–ú–µ—Å—Ç–∞–Ω ‚Äî —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –º–∞—Å—Ç–µ—Ä, —Å–æ—á–µ—Ç–∞—é—â–∏–π –≤ —Å–µ–±–µ —Ç–∞–ª–∞–Ω—Ç —Ç–æ–ø-—Å—Ç–∏–ª–∏—Å—Ç–∞ –∏ —ç–∫—Å–ø–µ—Ä—Ç–∞ –ø–æ –ø–µ—Ä–º–∞–Ω–µ–Ω—Ç–Ω–æ–º—É –º–∞–∫–∏—è–∂—É. –ï–µ –≥–ª—É–±–æ–∫–∏–µ –∑–Ω–∞–Ω–∏—è –ø–æ–∑–≤–æ–ª—è—é—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –∑–∞–∫–æ–Ω—á–µ–Ω–Ω—ã–µ –∏ –±–µ–∑—É–ø—Ä–µ—á–Ω—ã–µ –æ–±—Ä–∞–∑—ã, –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞—é—â–∏–µ –≤–∞—à—É –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ—Å—Ç—å.',
                'specialization': '–°—Ç–∏–ª–∏—Å—Ç –ø–æ –≤–æ–ª–æ—Å–∞–º, –ü–µ—Ä–º–∞–Ω–µ–Ω—Ç–Ω—ã–π –º–∞–∫–∏—è–∂',
                'years_of_experience': 18
            },
            'sabri': {
                'full_name': '–ú–æ—Ö–∞–º–º–µ–¥ –°–∞–±—Ä–∏',
                'photo': '/landing-images/staff/Simo.webp',
                'nickname': 'Simo',
                'email': 'sabrisimo363@gmail.com',
                'phone': '+971503477993',
                'bio': '–°–∏–º–æ —è–≤–ª—è–µ—Ç—Å—è –≤–µ–¥—É—â–∏–º —ç–∫—Å–ø–µ—Ä—Ç–æ–º –Ω–∞—à–µ–≥–æ —Å–∞–ª–æ–Ω–∞ –≤ –æ–±–ª–∞—Å—Ç–∏ –ø—Ä–µ–º–∏–∞–ª—å–Ω–æ–≥–æ —É—Ö–æ–¥–∞ –∏ —Å–ª–æ–∂–Ω–æ–≥–æ –∫–æ–ª–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è. –ï–≥–æ –º–Ω–æ–≥–æ–ª–µ—Ç–Ω–∏–π –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–π –æ–ø—ã—Ç –∏ –∞–≤—Ç–æ—Ä—Å–∫–∏–µ –º–µ—Ç–æ–¥–∏–∫–∏ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É—é—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã—Å–æ—á–∞–π—à–µ–≥–æ –∫–ª–∞—Å—Å–∞.',
                'specialization': '–¢–æ–ø-—Å—Ç–∏–ª–∏—Å—Ç, –ö–æ–ª–æ—Ä–∏—Å—Ç',
                'years_of_experience': 10
            },
            'jennifer': {
                'full_name': '–ü–µ—Ä–∞–¥–∏–ª—å—è –î–∂–µ–Ω–Ω–∏—Ñ–µ—Ä',
                'photo': '/landing-images/staff/Jennifer.webp',
                'nickname': 'Jennifer',
                'email': 'peradillajennifer47@gmail.com',
                'phone': '+971564208308',
                'bio': '–î–∂–µ–Ω–Ω–∏—Ñ–µ—Ä –≤–æ–ø–ª–æ—â–∞–µ—Ç –≤ —Å–µ–±–µ —Ç–∞–ª–∞–Ω—Ç –º–Ω–æ–≥–æ–ø—Ä–æ—Ñ–∏–ª—å–Ω–æ–≥–æ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞. –û–Ω–∞ –≤–∏—Ä—Ç—É–æ–∑–Ω–æ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∫–∞–∫ –±–∞–∑–æ–≤—ã–µ, —Ç–∞–∫ –∏ —Å–ª–æ–∂–Ω—ã–µ –±—å—é—Ç–∏-–ø—Ä–æ—Ü–µ–¥—É—Ä—ã, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∏ –≥–∞—Ä–º–æ–Ω–∏—á–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –≤–∞—à–µ–º—É –ø—Ä–µ–æ–±—Ä–∞–∂–µ–Ω–∏—é.',
                'specialization': '–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–∞—Å—Ç–µ—Ä –∫—Ä–∞—Å–æ—Ç—ã',
                'years_of_experience': 12
            },
            'lyazat': {
                'full_name': 'Kozhabay Lyazat',
                'photo': '/landing-images/staff/Lyazzat.webp',
                'nickname': 'Lyazat',
                'email': 'lazzat.kozhabaeva@mail.ru',
                'phone': '+971505303871',
                'bio': '–õ—è–∑–∞—Ç ‚Äî –∏—Å—Ç–∏–Ω–Ω—ã–π –ø–µ—Ä—Ñ–µ–∫—Ü–∏–æ–Ω–∏—Å—Ç –≤ –∏–Ω–¥—É—Å—Ç—Ä–∏–∏ –Ω–æ–≥—Ç–µ–≤–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞. –û–±–ª–∞–¥–∞—è –±–µ–∑—É–ø—Ä–µ—á–Ω—ã–º –≤–∫—É—Å–æ–º –∏ –≤–Ω–∏–º–∞–Ω–∏–µ–º –∫ –¥–µ—Ç–∞–ª—è–º, –æ–Ω–∞ —Å–æ–∑–¥–∞–µ—Ç –∏–¥–µ–∞–ª—å–Ω—ã–π –º–∞–Ω–∏–∫—é—Ä –∏ –ø–µ–¥–∏–∫—é—Ä, –∑–∞–±–æ—Ç—è—Å—å –æ–± —ç—Å—Ç–µ—Ç–∏–∫–µ –∏ –∑–¥–æ—Ä–æ–≤—å–µ –≤–∞—à–∏—Ö —Ä—É–∫.',
                'specialization': '–ù–æ–≥—Ç–µ–≤–æ–π —Å–µ—Ä–≤–∏—Å',
                'years_of_experience': 5
            }
        }
        
        for username, data in employee_data.items():
            c.execute("""
                UPDATE users SET 
                    full_name = %s,
                    photo = %s, 
                    nickname = %s,
                    email = %s,
                    phone = %s,
                    bio = %s,
                    specialization = %s,
                    years_of_experience = %s,
                    is_active = TRUE, 
                    is_service_provider = TRUE, 
                    is_public_visible = TRUE 
                WHERE username = %s OR full_name = %s
            """, (
                data['full_name'], data['photo'], data['nickname'], 
                data.get('email'), data.get('phone'),
                data['bio'], data['specialization'], data['years_of_experience'],
                username, data['full_name']
            ))
        log_info("   ‚úÖ Synchronized all employee detailed info", "maintenance")

        # 8. Merge duplicate employees (DEEP CLEANUP & DELETION)
        log_info("üë• Merging duplicate employees (Final Cleanup)...", "maintenance")
        
        staff_targets = [
            {'username': 'gulcehre', 'alternates': ['kasymova_gulcehre', 'gulya', 'gulcehre_archived'], 'names': ['Kasymova Gulcehre', '–ì—É–ª—å—á–µ—Ö—Ä–∞', '–ì—É–ª—è', '–ö–∞—Å—ã–º–æ–≤–∞ –ì—É–ª—å—á–µ—Ä–µ']},
            {'username': 'jennifer', 'alternates': ['peradilla_jennifer', 'jennifer_archived'], 'names': ['Peradilla Jennifer', '–ü–µ—Ä–∞–¥–∏–ª—å—è –î–∂–µ–Ω–Ω–∏—Ñ–µ—Ä', '–î–∂–µ–Ω–Ω–∏—Ñ–µ—Ä']},
            {'username': 'mestan', 'alternates': ['amandurdyyeva_mestan', 'mestan_archived'], 'names': ['Amandurdyyeva Mestan', '–ê–º–∞–Ω–¥—É—Ä–¥—ã–µ–≤–∞ –ú–µ—Å—Ç–∞–Ω', '–ú–µ—Å—Ç–∞–Ω']},
            {'username': 'sabri', 'alternates': ['mohamed_sabri', 'sabri_archived', 'simo'], 'names': ['Mohamed Sabri', '–ú–æ—Ö–∞–º–µ–¥ –°–∞–±—Ä–∏', '–ú–æ—Ö–∞–º–º–µ–¥ –°–∞–±—Ä–∏', '–°–∏–º–æ']},
            {'username': 'lyazat', 'alternates': ['kozhabay_lyazat', 'lyazat_archived'], 'names': ['Kozhabay Lyazat', '–ö–æ–∂–∞–±–∞–π –õ—è–∑–∞—Ç', '–õ—è–∑–∞—Ç']}
        ]

        for target in staff_targets:
            # Try to find the record that SHOULD be the master (Active one)
            c.execute("SELECT id FROM users WHERE username = %s AND is_active = TRUE LIMIT 1", (target['username'],))
            res = c.fetchone()
            if not res:
                # Find by any of the names and is_active
                c.execute("SELECT id FROM users WHERE full_name = ANY(%s) AND is_active = TRUE ORDER BY id DESC LIMIT 1", (target['names'],))
                res = c.fetchone()
                if not res: continue
                master_id = res[0]
            else:
                master_id = res[0]

            # Find ALL other users who might be duplicates
            c.execute("""
                SELECT id FROM users 
                WHERE (username IN %s OR username ILIKE ANY(%s) OR full_name = ANY(%s) OR full_name ILIKE ANY(%s)) 
                  AND id != %s
                  AND role NOT IN ('client', 'guest')
            """, (tuple(target['alternates'] + [target['username']]), 
                  [f"%{a}%" for a in target['alternates']], 
                  target['names'],
                  [f"%{n}%" for n in target['names']], 
                  master_id))
            
            duplicate_ids = [r[0] for r in c.fetchall()]

            for source_id in duplicate_ids:
                # Transfer data
                c.execute("""
                    UPDATE users t
                    SET 
                        bio = COALESCE(t.bio, s.bio),
                        specialization = COALESCE(t.specialization, s.specialization),
                        experience = COALESCE(t.experience, s.experience),
                        years_of_experience = COALESCE(t.years_of_experience, s.years_of_experience),
                        photo = COALESCE(t.photo, s.photo),
                        gender = COALESCE(t.gender, s.gender)
                    FROM users s
                    WHERE t.id = %s AND s.id = %s
                """, (master_id, source_id))
                
                # Re-assign related records
                tables_to_fix = [
                    ('bookings', 'employee_id'),
                    ('user_services', 'user_id'),
                    ('user_schedule', 'user_id'),
                    ('messages', 'sender_id'),
                    ('client_images', 'employee_id'),
                    ('payroll_transactions', 'employee_id'),
                    ('employee_documents', 'employee_id'),
                    ('notification_settings', 'user_id'),
                    ('attendance', 'employee_id'),
                    ('work_sessions', 'employee_id'),
                    ('salary_payments', 'employee_id'),
                    ('inventory_logs', 'user_id'),
                    ('broadcast_receivers', 'user_id'),
                    ('user_permissions', 'user_id')
                ]
                
                for table, col in tables_to_fix:
                    # Check if both table and column exist in public schema
                    c.execute("""
                        SELECT EXISTS (
                            SELECT 1 FROM information_schema.columns 
                            WHERE table_schema = 'public' 
                              AND table_name = %s 
                              AND column_name = %s
                        )
                    """, (table, col))
                    if c.fetchone()[0]:
                         c.execute(f"UPDATE {table} SET {col} = %s WHERE {col} = %s", (master_id, source_id))
                         if c.rowcount > 0:
                             log_info(f"      üîó Reassigned {c.rowcount} records from {table}", "maintenance")
                
                # DELETE DUPLICATE
                c.execute("DELETE FROM users WHERE id = %s", (source_id,))
                log_info(f"   üóëÔ∏è Deleted duplicate ID: {source_id}", "maintenance")

        log_info("   ‚úÖ Finished deep cleanup and deletion of staff duplicates", "maintenance")
        
        # 9. Ensure only providers are public
        c.execute("""
            UPDATE users SET is_public_visible = FALSE
            WHERE is_service_provider = FALSE AND is_public_visible = TRUE
        """)
        
        # 10. Fix service names capitalization
        log_info("‚úèÔ∏è  Fixing service names capitalization...", "maintenance")
        c.execute("""
            UPDATE services SET name = INITCAP(name) WHERE name ~ '^[–∞-—èa-z]';
        """)
        _normalize_core_service_names(c)

        # 12. Fix Usernames and Full Names for Active Staff
        log_info("üë§ Synchronizing staff with credentials...", "maintenance")
        from utils.utils import hash_password, verify_password

        staff_fixes = [
            ('gulcehre', '–ö–∞—Å—ã–º–æ–≤–∞ –ì—É–ª—å—á–µ—Ö—Ä–µ'),
            ('jennifer', '–ü–µ—Ä–∞–¥–∏–ª—å—è –î–∂–µ–Ω–Ω–∏—Ñ–µ—Ä'),
            ('mestan', 'Amandurdyyeva Mestan'),
            ('sabri', '–ú–æ—Ö–∞–º–º–µ–¥ –°–∞–±—Ä–∏'),
            ('lyazat', 'Kozhabay Lyazat')
        ]
        
        credentials_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "staff_credentials.txt")
        passwords = {}
        if os.path.exists(credentials_path):
            try:
                with open(credentials_path, "r", encoding="utf-8") as f:
                    curr_u = None
                    for line in f:
                        line = line.strip()
                        if line.startswith("Username: "): curr_u = line.replace("Username: ", "")
                        elif line.startswith("Password: ") and curr_u:
                            passwords[curr_u] = line.replace("Password: ", "")
                            curr_u = None
            except: pass

        for pref_u, pref_f in staff_fixes:
            c.execute("SELECT id, password_hash FROM users WHERE full_name = %s OR username = %s LIMIT 1", (pref_f, pref_u))
            u_data = c.fetchone()
            if u_data:
                u_id = u_data[0]
                c.execute("UPDATE users SET username = %s, full_name = %s, is_active = TRUE WHERE id = %s", (pref_u, pref_f, u_id))
                if pref_u in passwords:
                    if not u_data[1] or not verify_password(passwords[pref_u], u_data[1]):
                        c.execute("UPDATE users SET password_hash = %s WHERE id = %s", (hash_password(passwords[pref_u]), u_id))

        # Sync admin
        c.execute("SELECT id, password_hash FROM users WHERE username = 'admin'")
        admin_data = c.fetchone()
        if admin_data and 'admin' in passwords:
            if not admin_data[1] or not verify_password(passwords['admin'], admin_data[1]):
                c.execute("UPDATE users SET password_hash = %s WHERE username = 'admin'", (hash_password(passwords['admin']),))

        seed_notification_templates(c)

        conn.commit()
        log_info("üèÜ Data maintenance completed successfully!", "maintenance")
        return True

    except Exception as e:
        log_error(f"‚ùå Maintenance failed: {e}", "maintenance")
        try: conn.rollback()
        except: pass
        return False
    finally:
        try: c.execute("SELECT pg_advisory_unlock(12346)")
        except: pass
        try: conn.close()
        except: pass

def seed_notification_templates(c):
    """–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –±–∞–∑–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —à–∞–±–ª–æ–Ω–æ–≤ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π"""
    log_info("üé≠ Synchronizing notification templates...", "maintenance")
    
    templates = [
        {
            "name": "booking_confirmation",
            "category": "transactional",
            "subject": "–ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –∫ –º–∞—Å—Ç–µ—Ä—É",
            "body": "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ, {name}! \n\n–í—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–ø–∏—Å–∞–Ω—ã –≤ {salon_name}.\n\nüóì {date}\n‚è∞ {time}\nüíÜ {service}\nüë§ {master}\n\n–ë—É–¥–µ–º —Ä–∞–¥—ã –≤–∏–¥–µ—Ç—å –≤–∞—Å! –ï—Å–ª–∏ –≤–∞—à–∏ –ø–ª–∞–Ω—ã –∏–∑–º–µ–Ω—è—Ç—Å—è, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–æ–±—â–∏—Ç–µ –Ω–∞–º –∑–∞—Ä–∞–Ω–µ–µ.",
            "variables": '["name", "service", "master", "date", "time", "salon_name"]'
        },
        {
            "name": "booking_reminder",
            "category": "transactional",
            "subject": "–ù–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ –æ –∑–∞–ø–∏—Å–∏ - {salon_name}",
            "body": "–ù–∞–ø–æ–º–∏–Ω–∞–µ–º, —á—Ç–æ –≤—ã –∑–∞–ø–∏—Å–∞–Ω—ã —Å–µ–≥–æ–¥–Ω—è ({date}) –≤ {time} –Ω–∞ {service}. –ë—É–¥–µ–º —Ä–∞–¥—ã –≤–∞—Å –≤–∏–¥–µ—Ç—å!",
            "variables": '["name", "service", "date", "time", "salon_name"]'
        },
        {
            "name": "birthday_greeting",
            "category": "marketing",
            "subject": "{name}, —Å –¥–Ω–µ–º —Ä–æ–∂–¥–µ–Ω–∏—è! üéÅ",
            "body": "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ, {name}! \n\n–ü–æ–∑–¥—Ä–∞–≤–ª—è–µ–º –≤–∞—Å —Å –î–Ω–µ–º –†–æ–∂–¥–µ–Ω–∏—è! üéâ\n\n–í —á–µ—Å—Ç—å –≤–∞—à–µ–≥–æ –ø—Ä–∞–∑–¥–Ω–∏–∫–∞ –º—ã –ø–æ–¥–≥–æ—Ç–æ–≤–∏–ª–∏ –¥–ª—è –≤–∞—Å –æ—Å–æ–±–µ–Ω–Ω—ã–π –ø–æ–¥–∞—Ä–æ–∫ –æ—Ç {salon_name} ‚Äî —Å–∫–∏–¥–∫—É 15% –Ω–∞ –ª—é–±—É—é —É—Å–ª—É–≥—É!\n\n–í–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º –º–æ–∂–Ω–æ –≤ —Ç–µ—á–µ–Ω–∏–µ 7 –¥–Ω–µ–π.\n\n–ë—É–¥—å—Ç–µ –ø—Ä–µ–∫—Ä–∞—Å–Ω—ã –∏ —Å–∏—è–π—Ç–µ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å! ‚ú®",
            "variables": '["name", "salon_name"]'
        },
        {
            "name": "birthday_reminder_7d",
            "category": "marketing",
            "subject": "{name}, –≤–∞—à –¥–µ–Ω—å —Ä–æ–∂–¥–µ–Ω–∏—è —É–∂–µ —á–µ—Ä–µ–∑ –Ω–µ–¥–µ–ª—é! ‚ú®",
            "body": "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ, {name}! \n\n–ú—ã –∑–Ω–∞–µ–º, —á—Ç–æ –≤–∞—à –æ—Å–æ–±–µ–Ω–Ω—ã–π –¥–µ–Ω—å ‚Äî —á–µ—Ä–µ–∑ –Ω–µ–¥–µ–ª—é! üéâ\n\n–°–∞–º–æ–µ –≤—Ä–µ–º—è –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å—Å—è, —á—Ç–æ–±—ã —Å–∏—è—Ç—å –∏ –±—ã—Ç—å –Ω–∞ –≤—ã—Å–æ—Ç–µ. –ú—ã –ø–æ–¥–≥–æ—Ç–æ–≤–∏–ª–∏ –¥–ª—è –≤–∞—Å –ø–æ–¥–∞—Ä–æ–∫: –ø—Ä–æ–º–æ–∫–æ–¥ –Ω–∞ —Å–∫–∏–¥–∫—É 15% –Ω–∞ –ª—é–±—ã–µ —É—Å–ª—É–≥–∏ –Ω–∞—à–µ–≥–æ —Å–∞–ª–æ–Ω–∞!\n\nüéÅ –ü—Ä–æ–º–æ–∫–æ–¥: {promo_code}\n\n–ó–∞–ø–∏—à–∏—Ç–µ—Å—å –∑–∞—Ä–∞–Ω–µ–µ, —á—Ç–æ–±—ã –∑–∞–±—Ä–æ–Ω–∏—Ä–æ–≤–∞—Ç—å —É–¥–æ–±–Ω–æ–µ –≤—Ä–µ–º—è! –ñ–¥–µ–º –≤–∞—Å! üíñ",
            "variables": '["name", "promo_code", "salon_name"]'
        },
        {
            "name": "master_new_booking",
            "category": "transactional",
            "subject": "üîî –ù–æ–≤–∞—è –∑–∞–ø–∏—Å—å! - {datetime}",
            "body": "üîî –ù–æ–≤–∞—è –∑–∞–ø–∏—Å—å!\n\nüë§ –ö–ª–∏–µ–Ω—Ç: {client_name}\nüíÜ –£—Å–ª—É–≥–∞: {service}\nüìÖ –î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è: {datetime}\nüìû –¢–µ–ª–µ—Ñ–æ–Ω: {phone}\nüìã ID: #{booking_id}",
            "variables": '["client_name", "service", "datetime", "phone", "booking_id"]'
        },
        {
            "name": "master_booking_change",
            "category": "transactional",
            "subject": "‚úèÔ∏è –ó–∞–ø–∏—Å—å –∏–∑–º–µ–Ω–µ–Ω–∞! - {datetime}",
            "body": "‚úèÔ∏è –ó–∞–ø–∏—Å—å –∏–∑–º–µ–Ω–µ–Ω–∞!\n\nüë§ –ö–ª–∏–µ–Ω—Ç: {client_name}\nüíÜ –£—Å–ª—É–≥–∞: {service}\nüìÖ –ù–æ–≤–æ–µ –≤—Ä–µ–º—è: {datetime}\nüìû –¢–µ–ª–µ—Ñ–æ–Ω: {phone}\nüìã ID: #{booking_id}",
            "variables": '["client_name", "service", "datetime", "phone", "booking_id"]'
        },
        {
            "name": "master_booking_cancel",
            "category": "transactional",
            "subject": "‚ùå –ó–∞–ø–∏—Å—å –æ—Ç–º–µ–Ω–µ–Ω–∞! - {datetime}",
            "body": "‚ùå –ó–∞–ø–∏—Å—å –æ—Ç–º–µ–Ω–µ–Ω–∞!\n\nüë§ –ö–ª–∏–µ–Ω—Ç: {client_name}\nüíÜ –£—Å–ª—É–≥–∞: {service}\nüìÖ –ë—ã–ª–∞ –Ω–∞: {datetime}\nüìã ID: #{booking_id}",
            "variables": '["client_name", "service", "datetime", "booking_id"]'
        }
    ]

    for t in templates:
        c.execute("""
            INSERT INTO notification_templates 
            (name, category, subject, body, variables, is_system)
            VALUES (%s, %s, %s, %s, %s, TRUE)
            ON CONFLICT (name) DO UPDATE SET
                category = EXCLUDED.category,
                subject = EXCLUDED.subject,
                body = EXCLUDED.body,
                variables = EXCLUDED.variables,
                updated_at = CURRENT_TIMESTAMP
        """, (
            t['name'], t['category'], t['subject'], t['body'], t['variables']
        ))
    
    log_info(f"   ‚úÖ Synchronized {len(templates)} system templates", "maintenance")

if __name__ == "__main__":
    run_fix()
