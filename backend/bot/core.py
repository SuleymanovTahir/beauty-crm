# backend/bot/core.py
import google.generativeai as genai
import httpx
import os
import asyncio
from typing import Dict, Optional, List, Tuple
from datetime import datetime, timedelta

from config import GEMINI_API_KEY
from db import (
    get_salon_settings,
    get_bot_settings,
)


class SalonBot:
    """
    –ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å AI-–±–æ—Ç–∞ –¥–ª—è —Å–∞–ª–æ–Ω–∞ –∫—Ä–∞—Å–æ—Ç—ã

    –û—Ç–≤–µ—á–∞–µ—Ç –∑–∞:
    - –ó–∞–≥—Ä—É–∑–∫—É –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–∑ –ë–î
    - –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤
    - –ì–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–æ–≤ —á–µ—Ä–µ–∑ Gemini (—Å –ø—Ä–æ–∫—Å–∏)
    - –û–±—Ä–∞–±–æ—Ç–∫—É –ª–æ–≥–∏–∫–∏ –¥–∏–∞–ª–æ–≥–æ–≤
    """

    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ - –∑–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –ë–î"""
        self.reload_settings()

        # ‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–∫—Å–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –≥–µ–æ–±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
        environment = os.getenv("ENVIRONMENT")
        proxy_url_raw = os.getenv("PROXY_URL")

        print("=" * 50)
        print(f"üîç DEBUG: ENVIRONMENT = '{environment}'")
        print(f"üîç DEBUG: PROXY_URL exists = {proxy_url_raw is not None}")
        if proxy_url_raw:
            print(f"üîç DEBUG: PROXY_URL = '{proxy_url_raw[:30]}...'")

        self.proxy_url = proxy_url_raw if environment == "production" else None

        if self.proxy_url:
            print(f"‚úÖ –ü—Ä–æ–∫—Å–∏ –ê–ö–¢–ò–í–ï–ù: {self.proxy_url.split('@')[1] if '@' in self.proxy_url else self.proxy_url[:30]}...")
        else:
            print(f"‚ùå –ü—Ä–æ–∫—Å–∏ –û–¢–ö–õ–Æ–ß–ï–ù (env={environment}, proxy={proxy_url_raw is not None})")
        print("=" * 50)

        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º Gemini (–¥–ª—è fallback –±–µ–∑ –ø—Ä–æ–∫—Å–∏)
        genai.configure(api_key=GEMINI_API_KEY)
        self.model = genai.GenerativeModel('gemini-2.0-flash-exp')

        print("‚úÖ –ë–æ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (Gemini —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏)")

    def reload_settings(self):
        """–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –ë–î"""
        self.salon = get_salon_settings()
        self.bot_settings = get_bot_settings()
        print(f"‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {self.salon['name']}")

    def build_system_prompt(
        self,
        instagram_id: str,
        history: List[Tuple],
        booking_progress: Optional[Dict] = None,
        client_language: str = 'ru'
    ) -> str:
        """
        –ü–æ—Å—Ç—Ä–æ–∏—Ç—å system prompt –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ë–î

        Args:
            instagram_id: ID –∫–ª–∏–µ–Ω—Ç–∞ –≤ Instagram
            history: –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π
            booking_progress: –ü—Ä–æ–≥—Ä–µ—Å—Å –∑–∞–ø–∏—Å–∏ (deprecated)
            client_language: –Ø–∑—ã–∫ –∫–ª–∏–µ–Ω—Ç–∞ (ru/en/ar)

        Returns:
            str: –ü–æ–ª–Ω—ã–π system prompt –¥–ª—è Gemini
        """
        from .prompts import PromptBuilder

        builder = PromptBuilder(
            salon=self.salon,
            bot_settings=self.bot_settings
        )

        return builder.build_full_prompt(
            instagram_id=instagram_id,
            history=history,
            booking_progress=booking_progress or {},
            client_language=client_language
        )

    async def generate_response(
        self,
        user_message: str,
        instagram_id: str,
        history: Optional[List[Tuple]] = None,
        booking_progress: Optional[Dict] = None,
        client_language: str = 'ru'
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –∏—Å–ø–æ–ª—å–∑—É—è Gemini —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏

        Args:
            user_message: –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞
            instagram_id: ID –∫–ª–∏–µ–Ω—Ç–∞
            history: –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞
            booking_progress: –ü—Ä–æ–≥—Ä–µ—Å—Å –∑–∞–ø–∏—Å–∏
            client_language: –Ø–∑—ã–∫ –∫–ª–∏–µ–Ω—Ç–∞

        Returns:
            str: –û—Ç–≤–µ—Ç –±–æ—Ç–∞
        """
        # –ü–æ—Å—Ç—Ä–æ–∏—Ç—å system prompt
        system_prompt = self.build_system_prompt(
            instagram_id=instagram_id,
            history=history or [],
            booking_progress=booking_progress or {},
            client_language=client_language
        )
        full_prompt = f"{system_prompt}\n\nUser: {user_message}\nAssistant:"

        try:
            print("=" * 50)
            print("ü§ñ Generating AI response (Gemini via proxy)...")
            print(f"üìù User message: {user_message[:100]}")
            print(f"üë§ Instagram ID: {instagram_id}")
            print(f"üåê Language: {client_language}")
            supported = self.bot_settings.get('languages_supported', 'ru,en,ar')
            print(f"üóÇÔ∏è Supported langs from DB: {supported}")
            print(f"‚úÖ Client lang matches: {client_language in supported.split(',')}")
            print(f"üìä History length: {len(history) if history else 0}")

            # ‚úÖ –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–µ–º REST API —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏
            ai_response = await self._generate_via_proxy(full_prompt)

            print(f"‚úÖ AI response generated: {ai_response[:100]}")
            print("=" * 50)

            return ai_response

        except Exception as e:
            print("=" * 50)
            print(f"‚ùå Gemini API Error: {e}")
            print(f"üìã –¢–∏–ø –æ—à–∏–±–∫–∏: {type(e).__name__}")

            import traceback
            print(f"üìã –ü–æ–ª–Ω—ã–π traceback:\n{traceback.format_exc()}")
            print("=" * 50)

            return self._get_fallback_response(client_language)

    async def _generate_via_proxy(self, prompt: str, max_retries: int = 3) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ Gemini REST API —Å –ø—Ä–æ–∫—Å–∏ –∏ retry –º–µ—Ö–∞–Ω–∏–∑–º–æ–º"""
        url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key={GEMINI_API_KEY}"

        max_chars = self.bot_settings.get('max_message_chars', 500)
        max_tokens = int(max_chars / 2.5)

        prompt_with_limit = f"""{prompt}

    ‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –¢–≤–æ–π –æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –°–¢–†–û–ì–û –Ω–µ –±–æ–ª–µ–µ {max_chars} —Å–∏–º–≤–æ–ª–æ–≤! –ï—Å–ª–∏ –Ω–µ —É–ª–æ–∂–∏—à—å—Å—è - –æ–±—Ä–µ–∂—É—Ç –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ.
    """

        payload = {
            "contents": [{
                "parts": [{"text": prompt_with_limit}]
            }],
            "generationConfig": {
                "temperature": 0.7,
                "maxOutputTokens": max_tokens,
                "stopSequences": []
            }
        }

        if self.proxy_url:
            print(f"üåê –û—Ç–ø—Ä–∞–≤–∫–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏: {self.proxy_url.split('@')[1] if '@' in self.proxy_url else self.proxy_url[:30]}")
        else:
            print("‚ÑπÔ∏è –ü—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Gemini API (localhost —Ä–µ–∂–∏–º)")

        for attempt in range(max_retries):
            try:
                if self.proxy_url:
                    async with httpx.AsyncClient(timeout=60.0, follow_redirects=True, proxy=self.proxy_url) as client:
                        response = await client.post(url, json=payload)
                        data = response.json()
                else:
                    async with httpx.AsyncClient(timeout=60.0, follow_redirects=True) as client:
                        response = await client.post(url, json=payload)
                        data = response.json()

                # ‚úÖ –ü–†–û–í–ï–†–ö–ê 429 - RATE LIMIT
                if "error" in data:
                    error_code = data["error"].get("code")
                    error_msg = data["error"].get("message", "")

                    if error_code == 429:
                        if attempt < max_retries - 1:
                            wait_time = (2 ** attempt) * 2  # 2s, 4s, 8s
                            print(f"‚ö†Ô∏è Rate limit 429 (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}), –∂–¥—ë–º {wait_time}s...")
                            await asyncio.sleep(wait_time)
                            continue
                        else:
                            print(f"‚ùå Rate limit 429 –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
                            raise Exception("Rate limit exceeded after retries")
                    else:
                        raise Exception(f"Gemini API error {error_code}: {error_msg}")

                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
                if "candidates" in data and len(data["candidates"]) > 0:
                    candidate = data["candidates"][0]
                    if "content" in candidate and "parts" in candidate["content"]:
                        parts = candidate["content"]["parts"]
                        if len(parts) > 0 and "text" in parts[0]:
                            response_text = parts[0]["text"].strip()

                            if len(response_text) > max_chars:
                                response_text = response_text[:max_chars-3] + "..."

                            print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1})")
                            return response_text

                raise Exception(f"Unexpected Gemini response structure")

            except httpx.HTTPError as e:
                if attempt < max_retries - 1:
                    wait_time = (2 ** attempt) * 2
                    print(f"‚ùå HTTP Error (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}): {e}, retry —á–µ—Ä–µ–∑ {wait_time}s...")
                    await asyncio.sleep(wait_time)
                    continue
                print(f"‚ùå HTTP Error –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫: {e}")
                raise
            except Exception as e:
                if "Rate limit" in str(e) and attempt < max_retries - 1:
                    continue
                print(f"‚ùå Unexpected error: {e}")
                raise
            
        # –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã
        raise Exception("All retry attempts exhausted")

    def _get_fallback_response(self, language: str = 'ru') -> str:
        """–†–µ–∑–µ—Ä–≤–Ω—ã–π –æ—Ç–≤–µ—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ"""
        responses = {
            'ru': "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è —Å–µ–π—á–∞—Å –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω –∑–∞–ø—Ä–æ—Å–∞–º–∏ ü§ñ –ù–∞—à –º–µ–Ω–µ–¥–∂–µ—Ä —Å–∫–æ—Ä–æ –≤–∞–º –æ—Ç–≤–µ—Ç–∏—Ç! üíé",
            'en': "Sorry, I'm overloaded with requests ü§ñ Our manager will reply soon! üíé",
            'ar': "ÿπÿ∞ÿ±ÿßŸãÿå ÿ£ŸÜÿß ŸÖÿ≠ŸÖŸÑ ÿ®ÿßŸÑÿ∑ŸÑÿ®ÿßÿ™ ü§ñ ÿ≥Ÿäÿ±ÿØ ÿπŸÑŸäŸÉ ŸÖÿØŸäÿ±ŸÜÿß ŸÇÿ±Ÿäÿ®ÿßŸã! üíé"
        }
        return responses.get(language, responses['ru'])

    def should_greet(self, history: List[Tuple]) -> bool:
        """
        –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω—É–∂–Ω–æ –ª–∏ –∑–¥–æ—Ä–æ–≤–∞—Ç—å—Å—è

        Returns:
            bool: True –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–æ–∑–¥–æ—Ä–æ–≤–∞—Ç—å—Å—è
        """
        # –ï—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        if len(history) <= 1:
            return True

        # –ï—Å–ª–∏ –ø—Ä–æ—à–ª–æ –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ (>6 —á–∞—Å–æ–≤ + –Ω–æ–≤—ã–π –¥–µ–ª–æ–≤–æ–π –¥–µ–Ω—å)
        if len(history) > 0:
            try:
                last_msg = history[-1]
                last_timestamp = datetime.fromisoformat(last_msg[2])
                now = datetime.now()
                time_diff = now - last_timestamp

                if time_diff > timedelta(hours=6):
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–º–µ–Ω—É "–¥–µ–ª–æ–≤–æ–≥–æ –¥–Ω—è" (08:00 - —Å–ª–µ–¥—É—é—â–∏–π –¥–µ–Ω—å)
                    last_business_day = (
                        last_timestamp.date()
                        if last_timestamp.hour >= 8
                        else (last_timestamp - timedelta(days=1)).date()
                    )
                    current_business_day = (
                        now.date()
                        if now.hour >= 8
                        else (now - timedelta(days=1)).date()
                    )

                    return current_business_day > last_business_day
            except:
                pass

        return False


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –±–æ—Ç–∞
_bot_instance = None


def get_bot() -> SalonBot:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –±–æ—Ç–∞ (singleton)"""
    global _bot_instance
    if _bot_instance is None:
        _bot_instance = SalonBot()
    return _bot_instance