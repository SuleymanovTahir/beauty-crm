# backend/integrations/gemini.py
"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Google Gemini AI
"""
import google.generativeai as genai
from core.config import GEMINI_API_KEY, GEMINI_MODEL

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º Gemini
genai.configure(api_key=GEMINI_API_KEY)

async def ask_gemini(prompt: str, context: str = "", **kwargs) -> str:
    """
    –û—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫ Gemini AI
    
    Args:
        prompt: –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç
        context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (max_tokens, temperature, etc.)
    
    Returns:
        str: –û—Ç–≤–µ—Ç –æ—Ç AI –∏–ª–∏ fallback —Å–æ–æ–±—â–µ–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    model = genai.GenerativeModel(GEMINI_MODEL)
    full_prompt = f"{context}\n\n{prompt}" if context else prompt
    
    # Map max_tokens to max_output_tokens for Gemini
    generation_config = {}
    if 'max_tokens' in kwargs:
        generation_config['max_output_tokens'] = kwargs.pop('max_tokens')
    
    # Add any other kwargs to generation_config
    generation_config.update(kwargs)
    
    try:
        response = model.generate_content(full_prompt, generation_config=generation_config if generation_config else None)
        return response.text.strip()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ Gemini: {e}")
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –î–∞–≤–∞–π—Ç–µ –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑! üòä"