#!/usr/bin/env python3
"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ª—É—á—à–µ–π –±–µ—Å–ø–ª–∞—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏ Gemini
"""
import httpx
import asyncio
import time
from typing import Dict, List, Tuple
import os
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º .env.local
load_dotenv('.env.local')

GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')

# –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ, —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ)
PRIORITY_MODELS = [
    "gemini-2.5-flash",           # –ù–æ–≤–µ–π—à–∞—è Flash
    "gemini-2.0-flash",           # –°—Ç–∞–±–∏–ª—å–Ω–∞—è 2.0
    "gemini-2.0-flash-001",       # –í–µ—Ä—Å–∏–æ–Ω–Ω–∞—è 2.0
    "gemini-flash-latest",        # –ê–ª–∏–∞—Å –Ω–∞ –∞–∫—Ç—É–∞–ª—å–Ω—É—é
    "gemini-2.5-pro",             # –ú–æ—â–Ω–∞—è Pro
    "gemini-2.0-pro-exp",         # –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è Pro
    "gemini-2.5-flash-lite",      # –õ—ë–≥–∫–∞—è –≤–µ—Ä—Å–∏—è
    "gemini-2.0-flash-lite",      # –õ—ë–≥–∫–∞—è 2.0
]

async def check_model(model_name: str, key: str) -> Dict:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –æ–¥–Ω—É –º–æ–¥–µ–ª—å"""
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={key}"
    
    payload = {
        "contents": [{
            "parts": [{"text": "Hello, test"}]
        }],
        "generationConfig": {
            "temperature": 0.7,
            "maxOutputTokens": 50
        }
    }
    
    result = {
        "name": model_name,
        "status": "unknown",
        "response_time": None,
        "error": None,
        "working": False
    }
    
    try:
        start_time = time.time()
        
        async with httpx.AsyncClient(timeout=15.0) as client:
            response = await client.post(url, json=payload)
            
        response_time = time.time() - start_time
        result["response_time"] = round(response_time, 2)
        
        if response.status_code == 200:
            data = response.json()
            if "candidates" in data:
                result["status"] = "‚úÖ –†–ê–ë–û–¢–ê–ï–¢"
                result["working"] = True
                text = data["candidates"][0]["content"]["parts"][0]["text"]
                result["sample"] = text[:30] + "..." if len(text) > 30 else text
            else:
                result["status"] = "‚ö†Ô∏è –°—Ç—Ä–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç"
                
        elif response.status_code == 429:
            result["status"] = "‚è±Ô∏è RATE LIMIT"
            result["error"] = "–õ–∏–º–∏—Ç –∏—Å—á–µ—Ä–ø–∞–Ω"
            
        elif response.status_code == 404:
            result["status"] = "‚ùå –ù–ï –ù–ê–ô–î–ï–ù–ê"
            result["error"] = "–ú–æ–¥–µ–ª—å –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"
            
        elif response.status_code == 400:
            result["status"] = "‚ùå INVALID KEY"
            result["error"] = "–ö–ª—é—á –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω"
            
        elif response.status_code == 403:
            result["status"] = "‚ùå FORBIDDEN"
            result["error"] = "–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â—ë–Ω"
            
        else:
            result["status"] = f"‚ö†Ô∏è HTTP {response.status_code}"
            result["error"] = response.text[:100]
            
    except httpx.TimeoutException:
        result["status"] = "‚è±Ô∏è TIMEOUT"
        result["error"] = "–ù–µ –æ—Ç–≤–µ—Ç–∏–ª –∑–∞ 15 —Å–µ–∫—É–Ω–¥"
        
    except Exception as e:
        result["status"] = "‚ùå –û–®–ò–ë–ö–ê"
        result["error"] = str(e)[:100]
    
    return result

async def main():
    print("\n" + "="*70)
    print("üîç –ü–û–ò–°–ö –õ–£–ß–®–ï–ô –ë–ï–°–ü–õ–ê–¢–ù–û–ô –ú–û–î–ï–õ–ò GEMINI")
    print("="*70)
    print(f"üîë API Key: {GEMINI_API_KEY[:20]}...{GEMINI_API_KEY[-10:]}")
    print(f"üì¶ –ü—Ä–æ–≤–µ—Ä—è–µ–º {len(PRIORITY_MODELS)} –º–æ–¥–µ–ª–µ–π...")
    print("="*70)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ (–Ω–æ —Å –Ω–µ–±–æ–ª—å—à–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π)
    results = []
    for i, model in enumerate(PRIORITY_MODELS):
        print(f"\n[{i+1}/{len(PRIORITY_MODELS)}] –ü—Ä–æ–≤–µ—Ä—è–µ–º: {model}...", end=" ")
        result = await check_model(model, GEMINI_API_KEY)
        results.append(result)
        print(result["status"], end="")
        if result["response_time"]:
            print(f" ({result['response_time']}s)")
        else:
            print()
        
        # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        if i < len(PRIORITY_MODELS) - 1:
            await asyncio.sleep(0.5)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–∞–±–æ—Ç–∞—é—â–∏–µ –º–æ–¥–µ–ª–∏
    working_models = [r for r in results if r["working"]]
    
    print("\n" + "="*70)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´")
    print("="*70)
    
    if not working_models:
        print("‚ùå –ù–ò –û–î–ù–ê –ú–û–î–ï–õ–¨ –ù–ï –†–ê–ë–û–¢–ê–ï–¢!")
        print("\nüí° –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
        print("1. –í—Å–µ –º–æ–¥–µ–ª–∏ –∏—Å—á–µ—Ä–ø–∞–ª–∏ –ª–∏–º–∏—Ç ‚Üí –ü–æ–¥–æ–∂–¥–∏ 1-2 –º–∏–Ω—É—Ç—ã")
        print("2. API –∫–ª—é—á –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω ‚Üí –°–æ–∑–¥–∞–π –Ω–æ–≤—ã–π")
        print("3. –ü—Ä–æ–±–ª–µ–º—ã —Å —Å–µ—Ç—å—é ‚Üí –ü—Ä–æ–≤–µ—Ä—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ")
        print("\nüîó –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –∫–ª—é—á: https://aistudio.google.com/app/apikey")
        return
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–∫–æ—Ä–æ—Å—Ç–∏ (–±—ã—Å—Ç—Ä—ã–µ –ª—É—á—à–µ)
    working_models.sort(key=lambda x: x["response_time"])
    
    print(f"\n‚úÖ –†–∞–±–æ—Ç–∞—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π: {len(working_models)}")
    print("\nüèÜ –¢–û–ü-3 –õ–£–ß–®–ò–• –ú–û–î–ï–õ–ï–ô:\n")
    
    for i, model in enumerate(working_models[:3], 1):
        print(f"{i}. {model['name']}")
        print(f"   –°–∫–æ—Ä–æ—Å—Ç—å: {model['response_time']}s")
        if 'sample' in model:
            print(f"   –ü—Ä–∏–º–µ—Ä: {model['sample']}")
        print()
    
    # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é
    best_model = working_models[0]
    
    print("="*70)
    print("üéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø")
    print("="*70)
    print(f"\n‚úÖ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model['name']}")
    print(f"‚ö° –°–∫–æ—Ä–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞: {best_model['response_time']}s")
    print(f"üí∞ –°—Ç–∞—Ç—É—Å: –ë–µ—Å–ø–ª–∞—Ç–Ω–∞—è (Free Tier)")
    
    print("\nüìù –ß–¢–û –î–ï–õ–ê–¢–¨ –î–ê–õ–¨–®–ï:")
    print(f"\n1. –û—Ç–∫—Ä–æ–π —Ñ–∞–π–ª: backend/bot/core.py")
    print(f"\n2. –ù–∞–π–¥–∏ —Å—Ç—Ä–æ–∫—É ~52:")
    print(f"   self.model = genai.GenerativeModel('gemini-2.0-flash-exp')")
    print(f"\n   –ó–∞–º–µ–Ω–∏ –Ω–∞:")
    print(f"   self.model = genai.GenerativeModel('{best_model['name']}')")
    
    print(f"\n3. –ù–∞–π–¥–∏ —Å—Ç—Ä–æ–∫—É ~173:")
    print(f"   url = f\"...models/gemini-2.0-flash-exp:generateContent...\"")
    print(f"\n   –ó–∞–º–µ–Ω–∏ –Ω–∞:")
    print(f"   url = f\"...models/{best_model['name']}:generateContent...\"")
    
    print("\n4. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏ –±–æ—Ç–∞:")
    print("   python main.py")
    
    print("\n" + "="*70)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–æ–¥–µ–ª–∏ —Å rate limit
    rate_limited = [r for r in results if "RATE LIMIT" in r["status"]]
    if rate_limited:
        print(f"\n‚è±Ô∏è –ú–æ–¥–µ–ª–∏ —Å Rate Limit ({len(rate_limited)}):")
        for model in rate_limited:
            print(f"   ‚Ä¢ {model['name']}")
        print("   –ü–æ–¥–æ–∂–¥–∏ 1-2 –º–∏–Ω—É—Ç—ã –∏ –æ–Ω–∏ —Å–Ω–æ–≤–∞ –∑–∞—Ä–∞–±–æ—Ç–∞—é—Ç")
    
    print("\n" + "="*70)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é?")
    config_content = f"""# –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±—Ä–∞–Ω–∞ {time.strftime('%Y-%m-%d %H:%M:%S')})
GEMINI_MODEL={best_model['name']}
# –°–∫–æ—Ä–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞: {best_model['response_time']}s
# –û—Å—Ç–∞–ª—å–Ω—ã–µ —Ä–∞–±–æ—Ç–∞—é—â–∏–µ –º–æ–¥–µ–ª–∏:
{chr(10).join([f'# - {m["name"]} ({m["response_time"]}s)' for m in working_models[1:4]])}
"""
    
    with open('.gemini_best_model', 'w') as f:
        f.write(config_content)
    
    print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ .gemini_best_model")

if __name__ == "__main__":
    asyncio.run(main())